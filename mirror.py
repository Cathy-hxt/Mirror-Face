import os
import json
import cv2
import numpy as np
import datetime
import atexit
import time
import requests
import textwrap
from collections import Counter
import io
import threading
import tkinter as tk
from matplotlib import pyplot as plt
from matplotlib.patches import FancyArrowPatch
from PIL import Image, ImageDraw, ImageFont, ImageTk
from screeninfo import get_monitors
from deepface import DeepFace
from openai import OpenAI
from qianfan.resources.console.iam import IAM

# ------------------ å¸¸é‡é…ç½® ---------------------
# Face++ API é…ç½®
FACEPP_API_KEY = "qWTsV*************************"
FACEPP_API_SECRET = "abUp*************************"

# ç™¾åº¦åƒå¸† API é…ç½®
ACCESS_KEY_ID = "ALT*************************"
ACCESS_KEY_SECRET = "7149e*************************"

# æ–‡ä»¶è·¯å¾„é…ç½®
EMBEDDINGS_FILE = r"E:\emotion_db\face_embeddings.npz"
IDS_FILE = r"E:\emotion_db\face_ids.json"
LOGS_FILE = r"E:\emotion_db\emotion_logs.json"
FACE_DB_PATH = r"E:\emotion_db\face_db"  # å­˜å‚¨äººè„¸å›¾ç‰‡çš„æ•°æ®åº“ç›®å½•

# ------------------ åŠ è½½æŒä¹…åŒ–æ•°æ® ---------------------
if os.path.exists(EMBEDDINGS_FILE):
    data = np.load(EMBEDDINGS_FILE)
    known_face_embeddings = [data[key] for key in data.files]
else:
    known_face_embeddings = []

if os.path.exists(IDS_FILE):
    with open(IDS_FILE, 'r', encoding='utf-8') as f:
        known_face_ids = json.load(f)
else:
    known_face_ids = []

if os.path.exists(LOGS_FILE):
    with open(LOGS_FILE, 'r', encoding='utf-8') as f:
        emotion_logs = json.load(f)
else:
    emotion_logs = {}

# ------------------ ä¿å­˜æ•°æ® ---------------------
def save_state():
    """ä¿å­˜å½“å‰çš„æƒ…ç»ªè¯†åˆ«æ•°æ®ã€IDå’Œæ—¥å¿—åˆ°æ–‡ä»¶ã€‚"""
    if known_face_embeddings:
        np.savez(EMBEDDINGS_FILE, *known_face_embeddings)
    with open(IDS_FILE, 'w', encoding='utf-8') as f:
        json.dump(known_face_ids, f, ensure_ascii=False, indent=4)
    with open(LOGS_FILE, 'w', encoding='utf-8') as f:
        json.dump(emotion_logs, f, ensure_ascii=False, indent=4)

atexit.register(save_state)

# ------------------ Face++ API äººè„¸æ£€æµ‹ ---------------------
def facepp_detect(face_img):
    """ä½¿ç”¨Face++ APIè¿›è¡Œäººè„¸æ£€æµ‹å¹¶è¿”å›æƒ…ç»ªã€æ€§åˆ«ã€å¹´é¾„ç­‰å±æ€§ã€‚"""
    url = "https://api-cn.faceplusplus.com/facepp/v3/detect"
    ret, buf = cv2.imencode('.jpg', face_img)
    if not ret:
        print("å›¾åƒç¼–ç å¤±è´¥")
        return None
    files = {
        "image_file": ("face.jpg", buf.tobytes(), "image/jpeg")
    }
    params = {
        "api_key": FACEPP_API_KEY,
        "api_secret": FACEPP_API_SECRET,
        "return_attributes": "emotion,gender,age,beauty",
        "return_landmark": 0  # ä¸è¿”å›é¢éƒ¨å…³é”®ç‚¹
    }
    
    try:
        response = requests.post(url, files=files, params=params)
        result = response.json()
        return result
    except Exception as e:
        print(f"è¯·æ±‚å¤±è´¥ï¼š{str(e)}")
        return None

# ------------------ OpenCV äººè„¸æ£€æµ‹ ---------------------
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# ------------------ AI å¯¹è¯ API é…ç½® ---------------------
client = OpenAI(api_key="YOUR_API_KEY", base_url="https://api.openai.com")

# ------------------ æƒ…ç»ªè¡¨æƒ…æ˜ å°„ ---------------------
emotion_emoji = {
    "happiness": "ğŸ˜€", "neutral": "ğŸ˜", "sadness": "ğŸ˜", "anger": "ğŸ˜¡", "fear": "ğŸ˜¨",
    "disgust": "ğŸ˜·", "surprise": "ğŸ˜±", "unknown": "â“", "": ""
}

# ------------------ AI å¯¹è¯ç”Ÿæˆ ---------------------
def get_chat_response(name, emotion, gender, age, beauty_score):
    """æ ¹æ®ç”¨æˆ·çš„æƒ…ç»ªä¿¡æ¯ç”Ÿæˆå¯¹è¯å†…å®¹ã€‚"""
    prompt = f"User {name} is feeling {emotion}, gender: {gender}, *************************."
    completion = client.chat.completions.create(
        model="*************",
        messages=[{'role': 'user', 'content': prompt}]
    )
    return completion.choices[0].message.content.strip()

# ------------------ æƒ…ç»ªæ—¶é’Ÿç”Ÿæˆ ---------------------
def get_emotion_clock_img(person_id):
    """ä¸ºæŒ‡å®šçš„ç”¨æˆ·ç”Ÿæˆæƒ…ç»ªæ—¶é’Ÿå›¾åƒã€‚"""
    today = datetime.datetime.now().date().isoformat()
    person_logs = [log for log in emotion_logs.get(person_id, []) if log['timestamp'][:10] == today]
    hour_emotion = [""] * 12  # 7 AM åˆ° 6 PMï¼Œå…±12å°æ—¶
    hours = list(range(7, 19))

    for log in person_logs:
        timestamp = datetime.datetime.fromisoformat(log['timestamp'])
        best_hour = min(hours, key=lambda hour: abs((timestamp - timestamp.replace(hour=hour, minute=0)).total_seconds()))
        hour_emotion[best_hour - 7] = log['emotion']

    *************************
    
    print(f"æƒ…ç»ªæ—¶é’Ÿå·²ä¿å­˜åˆ° {output_path}")
    return img_cv

# ------------------ è¿è¡Œæ˜¾ç¤ºæƒ…ç»ªä¸å¯¹è¯ ---------------------
def show_dialog_clock_emotion(dialog_text, clock_img, most_common_emotion):
    """åœ¨å…¨å±ä¸‹ä¾æ¬¡æ˜¾ç¤ºæƒ…ç»ªè¡¨æƒ…ã€å¯¹è¯å†…å®¹ã€æƒ…ç»ªæ—¶é’Ÿ"""
    monitor = get_monitors()[1]
    screen_w, screen_h = monitor.width, monitor.height

    root = tk.Tk()
    root.overrideredirect(True)
    root.geometry(f"{screen_w}x{screen_h}+{monitor.x}+{monitor.y}")
    canvas = tk.Canvas(root, width=screen_w, height=screen_h, bg='black', highlightthickness=0)
    canvas.pack(fill='both', expand=True)

    def show_emoji():
        
        *************************

    def show_text():
           
        *************************
           
    def show_clock():
        
        *************************
            
    def clear_screen():
        canvas.delete("all")
        canvas.configure(bg='black')
        root.after(1000, root.destroy)  # 1ç§’åå…³é—­çª—å£

    root.after(500, show_emoji)  # 0.5ç§’åå¼€å§‹
    root.mainloop()

# ------------------ å¯åŠ¨é»‘å± ---------------------
def init_black_screen():
    """åˆå§‹åŒ–å¹¶å¯åŠ¨é»‘å±çª—å£ã€‚"""
    global black_root, black_canvas
    monitor = get_monitors()[1]
    black_root = tk.Tk()
    black_root.overrideredirect(True)
    black_root.geometry(f"{monitor.width}x{monitor.height}+{monitor.x}+{monitor.y}")
    black_canvas = tk.Canvas(black_root,
                             width=monitor.width,
                             height=monitor.height,
                             bg='black',
                             highlightthickness=0)
    black_canvas.pack(fill='both', expand=True)
    # å¼€å¯åå°çº¿ç¨‹è¿è¡Œä¸»å¾ªç¯ï¼Œä¸é˜»å¡åç»­é€»è¾‘
    threading.Thread(target=black_root.mainloop, daemon=True).start()
    
# å¯åŠ¨é»‘å±
init_black_screen()

# ------------------ æ‰“å¼€æ‘„åƒå¤´ ---------------------
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    raise RuntimeError("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")

# ------------------ åˆå§‹åŒ–çŠ¶æ€ ---------------------
face_present = False
face_start_time = None
face_end_time = None
recognizing = False
main_emotion_displayed = False
dialog_displaying = False
dialog_text = ""
dialog_start_time = None
clock_img = None
most_common_emotion = None
destroyWindow = False
black_root = None

# ------------------ äººè„¸æ£€æµ‹å’Œè¯†åˆ«ä¸»å¾ªç¯ ---------------------
while True:

    *************************

cap.release()
cv2.destroyAllWindows()
save_state()
print("ç¨‹åºç»“æŸï¼Œå·²ä¿å­˜æ‰€æœ‰æ•°æ®")
